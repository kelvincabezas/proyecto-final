import os
import requests
import numpy as np
import pandas as pd
import streamlit as st
import folium
from streamlit_folium import folium_static
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import plotly.express as px
import plotly.graph_objects as go

def show_modelo():
# T铆tulo y descripci贸n de la aplicaci贸n
    st.title('Modelo de Random Forest para Pesca Artesanal en Coishco')
    st.write("""
    Esta aplicaci贸n permite visualizar la importancia de las caracter铆sticas en un modelo de Random Forest para la predicci贸n del volumen de captura.
    """)

    # Cargar los datos
    df = pd.read_excel('data/data.xlsx')

    # Funci贸n para categorizar horas en intervalos de 2 horas
    def categorize_hour(hour):
        period = "A.M." if hour < 12 else "P.M."
        hour_12 = hour % 12
        hour_12 = 12 if hour_12 == 0 else hour_12
        start_hour = hour_12
        end_hour = (hour_12 + 2) % 12
        end_hour = 12 if end_hour == 0 else end_hour
        return f"{start_hour:02d} - {end_hour:02d} {period}"

    # Aplicar la funci贸n para categorizar horas en 'Hora_Faena'
    df['Hora_Faena'] = df['Inicio_Faena'].dt.hour.apply(categorize_hour)

    # Crear la columna 'Mes_Faena' y mapear los meses a abreviaturas
    meses = {1: 'ENE', 2: 'FEB', 3: 'MAR', 4: 'ABR', 5: 'MAY', 6: 'JUN', 
             7: 'JUL', 8: 'AGO', 9: 'SEP', 10: 'OCT', 11: 'NOV', 12: 'DIC'}
    df['Mes_Faena'] = df['Inicio_Faena'].dt.month.map(meses)

    # Crear rangos para 'Precio_Kg' y 'Talla_cm'
    bins_precio = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55]
    labels_precio = ["S/ (0 - 5)", "S/ (5 - 10)", "S/ (10 - 15)", "S/ (15 - 20)", 
                     "S/ (20 - 25)", "S/ (25 - 30)", "S/ (30 - 35)", "S/ (35 - 40)", 
                     "S/ (40 - 45)", "S/ (45 - 50)", "S/ (50 - 55)"]
    df['Precio_Float'] = pd.cut(df['Precio_Kg'], bins=bins_precio, labels=labels_precio, right=False)

    bins_talla = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]
    labels_talla = ["(10 - 20) cm", "(20 - 30) cm", "(30 - 40) cm", "(40 - 50) cm", 
                   "(50 - 60) cm", "(60 - 70) cm", "(70 - 80) cm", "(80 - 90) cm", 
                   "(90 - 100) cm", "(100 - 110) cm", "(110 - 120) cm", "(120 - 130) cm", 
                   "(130 - 140) cm", "(140 - 150) cm"]
    df['Talla_Float'] = pd.cut(df['Talla_cm'], bins=bins_talla, labels=labels_talla, right=False)

    # Selecci贸n del enfoque para las predicciones
    opcion = st.selectbox("Seleccionar el enfoque", ["Embarcaci贸n", "Especie"], key="enfoque_selectbox")

    # Filtrar seg煤n la opci贸n seleccionada
    if opcion == "Embarcaci贸n":
        seleccion = st.selectbox("Seleccionar la embarcaci贸n", df['Embarcacion'].unique(), key="embarcacion_selectbox")
        df_seleccion = df[df['Embarcacion'] == seleccion]
    else:
        seleccion = st.selectbox("Seleccionar la especie", df['Especie'].unique(), key="especie_selectbox")
        df_seleccion = df[df['Especie'] == seleccion]

    # Mostrar la imagen si la opci贸n es "Especie"
    if opcion == "Especie":
        especie_seleccionada = seleccion
        ruta_imagen = f"resources/{especie_seleccionada}.png"
        
        try:
            st.image(ruta_imagen, caption=f"Especie: {especie_seleccionada}", use_column_width=True)
        except FileNotFoundError:
            st.error(f"No se encontr贸 la imagen para la especie: {especie_seleccionada}")

    # Mostrar el mapa centrado en la ubicaci贸n de las capturas
    st.subheader(f"Mapa de capturas para la selecci贸n: {seleccion}")
    if not df_seleccion.empty:
        mapa = folium.Map(location=[df_seleccion['Origen_Latitud'].mean(), df_seleccion['Origen_Longitud'].mean()], zoom_start=6)
        for idx, row in df_seleccion.iterrows():
            folium.Marker(
                location=[row['Origen_Latitud'], row['Origen_Longitud']],
                popup=row['Especie'] if opcion == "Especie" else row['Embarcacion']
            ).add_to(mapa)
        folium_static(mapa)
    else:
        st.warning("No hay datos disponibles para la selecci贸n realizada.")

    # Definir las caracter铆sticas y la variable objetivo
    selected_columns = ['Caballos_Motor', 'Millas_Recorridas', 'Precio_Kg', 'Talla_cm', 
                       'Costo_Combustible', 'Ganancia', 'Temperatura_Agua_掳C', 
                       'Profundidad_m', 'Salinidad_PSU', 'Velocidad_Viento_m_s',
                       'Corriente_Marina_m_s', 'CPUE']

    # Verificar si las columnas existen en el DataFrame
    missing_columns = [col for col in selected_columns + ['Volumen_Kg'] if col not in df.columns]
    if missing_columns:
        st.error(f"Faltan las siguientes columnas en los datos: {missing_columns}")
        return

    # Normalizar los datos
    scaler = MinMaxScaler()
    df_normalized = df.copy()
    df_normalized[selected_columns] = scaler.fit_transform(df[selected_columns])

    X = df_normalized[selected_columns]
    y = df_normalized['Volumen_Kg']

    # Entrenar modelo de Random Forest
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
    modelo_rf = RandomForestRegressor(n_estimators=100, random_state=42)
    modelo_rf.fit(X_train, y_train)

    # Funci贸n generar_prediccion
    def generar_prediccion(caballos_motor, millas_recorridas, precio_kg, talla_cm, 
                       costo_combustible, ganancia, temperatura_agua, profundidad, 
                       salinidad, velocidad_viento, corriente_marina, cpue):
        # Crear un nuevo conjunto de datos con los valores ingresados
        nuevos_datos = np.array([[caballos_motor, millas_recorridas, precio_kg, talla_cm, 
                                costo_combustible, ganancia, temperatura_agua, profundidad, 
                                salinidad, velocidad_viento, corriente_marina, cpue]])

        # Normalizar los nuevos datos usando el scaler
        nuevos_datos_normalizados = scaler.transform(nuevos_datos)

        # Predicci贸n del modelo con los datos ingresados
        prediccion = modelo_rf.predict(nuevos_datos_normalizados)
        
        return prediccion[0]

    # Gr谩fico Interactivo: Curvas de Entrenamiento y Validaci贸n
    st.write("### Evaluaci贸n del Modelo")

    # Predicci贸n en el conjunto de validaci贸n
    y_pred = modelo_rf.predict(X_val)

    # C谩lculo de las m茅tricas
    mse = mean_squared_error(y_val, y_pred)
    mae = mean_absolute_error(y_val, y_pred)
    r2 = r2_score(y_val, y_pred)

    # Mostrar las m茅tricas
    st.markdown("**M茅tricas de Evaluaci贸n del Modelo:**")
    st.write(f"**Error Cuadr谩tico Medio (MSE):** {mse:.4f}")
    st.write(f"**Error Absoluto Medio (MAE):** {mae:.4f}")
    st.write(f"**Coeficiente de Determinaci贸n (R虏):** {r2:.4f}")

    # Explicaci贸n de las m茅tricas
    st.markdown("""
    - **Error Cuadr谩tico Medio (MSE):** Mide el promedio de los errores al cuadrado entre los valores reales y los predichos. Un valor menor indica un mejor desempe帽o del modelo.
    - **Error Absoluto Medio (MAE):** Representa el promedio de los errores absolutos entre los valores reales y los predichos. Es 煤til para entender el error promedio en las predicciones.
    - **Coeficiente de Determinaci贸n (R虏):** Indica la proporci贸n de la variabilidad de la variable dependiente que es explicada por el modelo. Un valor cercano a 1 sugiere un buen ajuste.
    """)

    st.subheader(f'Valores Reales vs Predichos - {seleccion} ({opcion})')
    st.markdown("""
    Este gr谩fico compara nuestras predicciones con los valores reales observados. Si los puntos se alinean bien con la l铆nea diagonal, significa que nuestro modelo est谩 haciendo un buen trabajo prediciendo el volumen de captura.
    """)
    # Gr谩fico de Valores Reales vs Predichos
    fig_real_vs_pred = px.scatter(x=y_val, y=y_pred, labels={'x': 'Valores Reales', 'y': 'Valores Predichos'},
                                  title='Valores Reales vs Predichos')
    fig_real_vs_pred.add_shape(type="line",
                               x0=y_val.min(), y0=y_val.min(),
                               x1=y_val.max(), y1=y_val.max(),
                               line=dict(color="Red", dash="dash"))
    st.plotly_chart(fig_real_vs_pred, use_container_width=True)

    # Gr谩fico de Curvas de Aprendizaje
    st.write("#### Curvas de Aprendizaje")
    st.markdown("Selecciona el n煤mero de 谩rboles para visualizar c贸mo afecta al desempe帽o del modelo.")

    # Selecci贸n del rango de n_estimators
    n_estimators_range = st.slider("Selecciona el rango de n_estimators", 10, 200, (10, 100), step=10)

    # Preparar los rangos
    n_estimators_list = list(range(n_estimators_range[0], n_estimators_range[1]+1, 10))
    train_scores = []
    val_scores = []

    for n in n_estimators_list:
        modelo = RandomForestRegressor(n_estimators=n, random_state=42)
        modelo.fit(X_train, y_train)
        train_score = modelo.score(X_train, y_train)
        val_score = modelo.score(X_val, y_val)
        train_scores.append(train_score)
        val_scores.append(val_score)

    # Crear el gr谩fico de curvas de aprendizaje
    fig_learning = go.Figure()
    fig_learning.add_trace(go.Scatter(x=n_estimators_list, y=train_scores, mode='lines+markers', name='Entrenamiento'))
    fig_learning.add_trace(go.Scatter(x=n_estimators_list, y=val_scores, mode='lines+markers', name='Validaci贸n'))
    fig_learning.update_layout(title='Curvas de Aprendizaje',
                               xaxis_title='N煤mero de rboles (n_estimators)',
                               yaxis_title='Puntuaci贸n R虏',
                               yaxis=dict(range=[0,1]))
    st.plotly_chart(fig_learning, use_container_width=True)
    
    # Cargar la clave de RapidAPI desde los secretos de Streamlit
    rapidapi_key = st.secrets["RAPIDAPI"]["key"]

    # Funci贸n para generar la predicci贸n basada en la entrada del usuario
    def generar_respuesta_rapidapi(prediccion, user_inputs):
        url = "https://cheapest-gpt-4-turbo-gpt-4-vision-chatgpt-openai-ai-api.p.rapidapi.com/v1/chat/completions"
        
        prompt = f"""
        El modelo predice un volumen capturado de {prediccion:.2f} kg basado en los siguientes datos:
        - Caballos de Motor: {user_inputs['caballos_motor']}
        - Millas Recorridas: {user_inputs['millas_recorridas']}
        - Precio por Kg: {user_inputs['precio_kg']}
        - Talla del Pescado: {user_inputs['talla_cm']}
        - Costo de Combustible: {user_inputs['costo_combustible']}
        - Ganancia: {user_inputs['ganancia']}
        - Temperatura del Agua: {user_inputs['temperatura_agua']} 掳C
        - Profundidad del Mar: {user_inputs['profundidad']} metros
        - Salinidad: {user_inputs['salinidad']} PSU
        - Velocidad del Viento: {user_inputs['velocidad_viento']} m/s
        - Corriente Marina: {user_inputs['corriente_marina']} m/s
        - ndice CPUE: {user_inputs['cpue']}

        Explica en lenguaje simple c贸mo estos factores pueden influir en el volumen de captura predicho.
        """

        payload = {
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "model": "gpt-4o",
            "max_tokens": 1000,
            "temperature": 0.7
        }
        headers = {
            "x-rapidapi-key": rapidapi_key,
            "x-rapidapi-host": "cheapest-gpt-4-turbo-gpt-4-vision-chatgpt-openai-ai-api.p.rapidapi.com",
            "Content-Type": "application/json"
        }

        try:
            response = requests.post(url, json=payload, headers=headers)
            response.raise_for_status()  # Raise an exception for bad status codes
            result = response.json()
            return result['choices'][0]['message']['content'].strip()
        except requests.RequestException as e:
            st.error(f"Error al comunicarse con la API de RapidAPI: {e}")
            return ""
        except Exception as e:
            st.error(f"Error inesperado: {e}")
            return ""

    # Interfaz del GPT en Streamlit
    st.header("Formulario para Predicci贸n de Volumen Capturado con Explicaci贸n")

    # Campos de entrada para el usuario
    caballos_motor = st.slider("Caballos de Motor", 10, 50, 20)
    millas_recorridas = st.slider("Millas Recorridas", 1, 100, 10)
    precio_kg = st.slider("Precio por Kg", 1.0, 55.0, 15.0)  # Ajustado para coincidir con bins_precio
    talla_cm = st.slider("Talla del Pescado (cm)", 10, 150, 30)  # Ajustado para coincidir con bins_talla
    costo_combustible = st.slider("Costo de Combustible (S/.)", 10.0, 1000.0, 100.0)
    ganancia = st.slider("Ganancia (S/.)", 50.0, 5000.0, 500.0)
    temperatura_agua = st.slider("Temperatura del Agua (掳C)", 15.0, 30.0, 25.0)
    profundidad = st.slider("Profundidad del Mar (m)", 10.0, 100.0, 50.0)
    salinidad = st.slider("Salinidad del Agua (PSU)", 30.0, 40.0, 35.0)
    velocidad_viento = st.slider("Velocidad del Viento (m/s)", 1.0, 20.0, 5.0)
    corriente_marina = st.slider("Corriente Marina (m/s)", 0.1, 2.0, 0.5)
    cpue = st.slider("ndice CPUE", 0.1, 5.0, 1.0)

    # Variable de control para mostrar el gr谩fico
    mostrar_grafico = False

    # Cuando el usuario env铆a los datos
    if st.button("Generar Predicci贸n y Explicaci贸n"):
        # Almacenar las entradas del usuario en un diccionario
        user_inputs = {
            'caballos_motor': caballos_motor,
            'millas_recorridas': millas_recorridas,
            'precio_kg': precio_kg,
            'talla_cm': talla_cm,
            'costo_combustible': costo_combustible,
            'ganancia': ganancia,
            'temperatura_agua': temperatura_agua,
            'profundidad': profundidad,
            'salinidad': salinidad,
            'velocidad_viento': velocidad_viento,
            'corriente_marina': corriente_marina,
            'cpue': cpue
        }
        
        # Generar la predicci贸n usando el modelo
        prediccion = generar_prediccion(caballos_motor, millas_recorridas, precio_kg, talla_cm, 
                                        costo_combustible, ganancia, temperatura_agua, profundidad, 
                                        salinidad, velocidad_viento, corriente_marina, cpue)

        # Mostrar predicci贸n de forma m谩s llamativa
        st.markdown(f"""
            <div style="text-align: center; padding: 20px; 
                        background-color: rgba(0, 0, 0, 0); 
                        border-radius: 10px; 
                        border: 2px solid #eb5952;">
                <h3 style="color: #93c7fa;"> Predicci贸n del Volumen Capturado (Kg) basado en los datos ingresados:</h3>
                <p style="font-size: 28px; font-weight: bold; 
                        color: #ec5a53;">{prediccion:.2f} Kg</p>
            </div>
        """, unsafe_allow_html=True)
        
        # Usar API para generar una respuesta explicativa basada en los datos
        explicacion = generar_respuesta_rapidapi(prediccion, user_inputs)
        
        # A帽adir un espacio antes de mostrar la explicaci贸n
        st.markdown("<br>", unsafe_allow_html=True)

        # Mostrar la respuesta generada por API
        if explicacion:
            with st.container():
                st.markdown("### Explicaci贸n")
                st.markdown(f"{explicacion}")
        
        # Cambiar la variable de control para mostrar el gr谩fico
        mostrar_grafico = True

    # Mostrar el gr谩fico solo si se ha generado la predicci贸n y la explicaci贸n
    if mostrar_grafico:
        # Gr谩fico de importancia de caracter铆sticas
        importances = modelo_rf.feature_importances_
        indices = X.columns
        feature_importances = pd.Series(importances, index=indices).sort_values(ascending=False)

        st.subheader('Importancia de Caracter铆sticas')
        st.markdown("""
        La importancia de caracter铆sticas nos ayuda a entender cu谩les variables son m谩s influyentes en la predicci贸n del volumen de captura.
        """)
        fig = px.bar(feature_importances, x=feature_importances.index, y=feature_importances.values,
                    title="Importancia de las Caracter铆sticas para Predicci贸n",
                    labels={'x': 'Caracter铆sticas', 'y': 'Importancia'})
        st.plotly_chart(fig, use_container_width=True)

        # Mostrar la caracter铆stica m谩s influyente
        caracteristica_principal = feature_importances.idxmax()
        st.markdown(f"**La caracter铆stica m谩s influyente es:** `{caracteristica_principal}`, lo que indica que esta variable tiene el mayor impacto en la predicci贸n del volumen de captura.")

# Ejecutar la funci贸n display si el script es el principal
if __name__ == "__main__":
    display()